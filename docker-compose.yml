version: '3'

services:
  # Python Service
  app:
    depends_on:
      - worker
      - scheduler
      - redis
    build:
      context: .
      dockerfile: docker/Dockerfile
    image: registry.thedeathstarco.com/elitedoc/api:dev
    container_name: api
    restart: unless-stopped
    tty: true
    ports:
      - '5000:5000'
    environment:
      BOILERPLATE_ENV: dev
      REDIS_URL: redis://redis
    working_dir: /app
    volumes:
      - ./:/app
      - ./docker/.env.local:/app/.env
    networks:
      - app-network

  # Background Worker
  worker:
    depends_on:
      - redis
    build:
      context: .
      dockerfile: docker/Dockerfile
    image: registry.thedeathstarco.com/elitedoc/api:dev
    container_name: worker
    restart: unless-stopped
    tty: true
    environment:
      BOILERPLATE_ENV: dev
      REDIS_URL: redis://redis
      SCRAPYJS_URL: http://scrapyjs:8050
    working_dir: /app
    command: ['python', 'manage.py', 'worker', 'default']
    volumes:
      - ./:/app
      - ./docker/.env.local:/app/.env
    networks:
      - app-network

  # Background Schedule Worker
  scheduler:
    depends_on:
      - redis
    build:
      context: .
      dockerfile: docker/Dockerfile
    image: registry.thedeathstarco.com/elitedoc/api:dev
    container_name: scheduler
    restart: unless-stopped
    tty: true
    working_dir: /app
    command: ['rqscheduler', '--host', 'redis']
    volumes:
      - ./:/app
      - ./docker/.env.local:/app/.env
    networks:
      - app-network

  redis:
    image: redis
    container_name: redis
    expose:
      - 6379
    networks:
      - app-network

  # Browser Javascript Engine
  scrapyjs:
    image: scrapinghub/splash
    container_name: scrapyjs
    expose:
      - 8050
    networks:
      - app-network

# Docker Networks
networks:
  app-network:
    driver: bridge
